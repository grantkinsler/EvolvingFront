{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0aa667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib\n",
    "# from adjustText import adjust_text\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import gzip\n",
    "# from cyvcf2 import VCF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "home_dir = '~/Documents/Stanford/Research/EvolvingFront'\n",
    "home_dir = os.path.expanduser(home_dir)\n",
    "\n",
    "tools_path = f'{home_dir}/code/processing/tools/tools.py'\n",
    "sys.path.append(os.path.dirname(os.path.expanduser(tools_path)))\n",
    "import tools as tools\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db184921",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = p.read_csv(f'{home_dir}/data/WGS/EvolvingFront_WGS_SNPs_by_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffe00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_hits = {}\n",
    "\n",
    "for info in snps['all_information'].values:\n",
    "    genes_found_here = []\n",
    "    for mutation in info.split('~'):\n",
    "    \n",
    "        if len(mutation.split(':')) == 9:\n",
    "            (chrom,pos,ref,alt,gene,effect,hgvs_c,hgvs_p,call) =  mutation.split(':')\n",
    "            if gene not in genes_found_here:\n",
    "                if gene not in gene_hits:\n",
    "                    gene_hits[gene] = [f'{effect}:{hgvs_c}:{hgvs_p}:{call}']\n",
    "                elif f'{effect}:{hgvs_c}:{hgvs_p}:{call}' not in gene_hits[gene]:\n",
    "                    gene_hits[gene].append(f'{effect}:{hgvs_c}:{hgvs_p}:{call}')\n",
    "                genes_found_here.append(gene)\n",
    "\n",
    "gene_hit_count = {gene:len(effects) for gene,effects in gene_hits.items()}\n",
    "\n",
    "gene_hit_df = p.DataFrame(columns=['gene','count','effects'])\n",
    "gene_hit_df['gene'] = gene_hit_count.keys()\n",
    "gene_hit_df['count'] = gene_hit_count.values()\n",
    "gene_hit_df['effects'] = gene_hits.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cbdca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_hit_df.sort_values('count',ascending=False).to_csv(f'{home_dir}/data/WGS/intermediate_files/EvolvingFront_WGS_RepeatHitGenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03be64d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>count</th>\n",
       "      <th>effects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KSP1</td>\n",
       "      <td>68</td>\n",
       "      <td>[frameshift_variant:c.1529delT:p.Phe510fs:1/1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>PUF3</td>\n",
       "      <td>28</td>\n",
       "      <td>[stop_gained:c.1519C&gt;T:p.Gln507*:1/1, stop_gai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RTG2</td>\n",
       "      <td>15</td>\n",
       "      <td>[missense_variant:c.989G&gt;T:p.Ser330Ile:1/1, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>PAB1</td>\n",
       "      <td>13</td>\n",
       "      <td>[missense_variant:c.127G&gt;C:p.Gly43Arg:1/1, mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>CIT1</td>\n",
       "      <td>13</td>\n",
       "      <td>[missense_variant:c.1307G&gt;T:p.Gly436Val:1/1, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>YNK1</td>\n",
       "      <td>1</td>\n",
       "      <td>[upstream_gene_variant:c.-1469A&gt;T:nan:1/1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tV(AAC)G2</td>\n",
       "      <td>1</td>\n",
       "      <td>[synonymous_variant:c.54G&gt;A:p.Gln18Gln:1/1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>CWH43</td>\n",
       "      <td>1</td>\n",
       "      <td>[missense_variant:c.1765G&gt;A:p.Val589Ile:1/1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>RQC2</td>\n",
       "      <td>1</td>\n",
       "      <td>[missense_variant:c.2251G&gt;A:p.Glu751Lys:0/1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>HLR1</td>\n",
       "      <td>1</td>\n",
       "      <td>[missense_variant:c.854A&gt;G:p.Gln285Arg:1/1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gene  count                                            effects\n",
       "5         KSP1     68  [frameshift_variant:c.1529delT:p.Phe510fs:1/1,...\n",
       "110       PUF3     28  [stop_gained:c.1519C>T:p.Gln507*:1/1, stop_gai...\n",
       "104       RTG2     15  [missense_variant:c.989G>T:p.Ser330Ile:1/1, mi...\n",
       "161       PAB1     13  [missense_variant:c.127G>C:p.Gly43Arg:1/1, mis...\n",
       "109       CIT1     13  [missense_variant:c.1307G>T:p.Gly436Val:1/1, m...\n",
       "..         ...    ...                                                ...\n",
       "165       YNK1      1         [upstream_gene_variant:c.-1469A>T:nan:1/1]\n",
       "164  tV(AAC)G2      1        [synonymous_variant:c.54G>A:p.Gln18Gln:1/1]\n",
       "163      CWH43      1       [missense_variant:c.1765G>A:p.Val589Ile:1/1]\n",
       "159       RQC2      1       [missense_variant:c.2251G>A:p.Glu751Lys:0/1]\n",
       "405       HLR1      1        [missense_variant:c.854A>G:p.Gln285Arg:1/1]\n",
       "\n",
       "[406 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_hit_df.sort_values('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6eada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_sorted = np.asarray(list(gene_hit_count.keys()))[np.argsort(list(gene_hit_count.values()))[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c04866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh oh - both IRA1_NON and CYR1   removing: EvolvingFront_WGS_Plate4_B05\n",
      "uh oh - both IRA1_NON and CYR1   removing: EvolvingFront_WGS_Plate4_B07\n",
      "uh oh - both GPB2 and CYR1   removing: EvolvingFront_WGS_Plate4_E02\n",
      "uh oh - both GPB2 and TOR1   removing: EvolvingFront_WGS_Plate5_C01\n"
     ]
    }
   ],
   "source": [
    "ancestral_mutations = {'IRA1_NON':'II:522427:A:T:IRA1:stop_gained:c.4202T>A:p.Leu1401*:1/1',\n",
    "                      'IRA1_MIS':'II:522697:G:A:IRA1:missense_variant:c.3932C>T:p.Ala1311Val:1/1',\n",
    "                      'CYR1':'X:427906:C:A:CYR1:missense_variant:c.2750C>A:p.Ser917Tyr:1/1',\n",
    "                      'GPB2':'I:40104:T:G:GPB2:stop_gained:c.846T>G:p.Tyr282*:1/1',\n",
    "                      'TOR1':'X:564551:T:G:TOR1:missense_variant:c.5136T>G:p.Phe1712Leu:1/1'}\n",
    "\n",
    "ancestral_mutations = {'IRA1_NON':'II:522427:A:T:IRA1:stop_gained:c.4202T>A:p.Leu1401*',\n",
    "                      'IRA1_MIS':'II:522697:G:A:IRA1:missense_variant:c.3932C>T:p.Ala1311Val',\n",
    "                      'CYR1':'X:427906:C:A:CYR1:missense_variant:c.2750C>A:p.Ser917Tyr',\n",
    "                      'GPB2':'I:40104:T:G:GPB2:stop_gained:c.846T>G:p.Tyr282*',\n",
    "                      'TOR1':'X:564551:T:G:TOR1:missense_variant:c.5136T>G:p.Phe1712Leu'}\n",
    "\n",
    "ancestral_mutations_map = {value:key for key,value in ancestral_mutations.items()}\n",
    "\n",
    "ancestors = []\n",
    "\n",
    "mixed_ancestor_calls = []\n",
    "\n",
    "for sample,info in zip(snps['sample'].values,snps['all_information'].values):\n",
    "#     mutation_list = all_information.split('~')\n",
    "    mutation_list = list([':'.join(x.split(':')[:-1]) for x in info.split('~')])\n",
    "    ancestor = np.nan\n",
    "    for mutation in mutation_list:\n",
    "        if mutation in ancestral_mutations_map.keys():\n",
    "            if not p.isnull(ancestor):\n",
    "                print(f'uh oh - both {ancestor} and {ancestral_mutations_map[mutation]  }','  removing:',sample)\n",
    "                mixed_ancestor_calls.append(sample)\n",
    "                ancestor = np.nan            \n",
    "            else:\n",
    "                ancestor = ancestral_mutations_map[mutation]  \n",
    "#         ancestor = ancestral_mutations_map[mutation]\n",
    "    ancestors.append(ancestor)\n",
    "\n",
    "snps['ancestor'] = ancestors\n",
    "snps = snps[~snps['sample'].isin(mixed_ancestor_calls)]\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ac4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2\n",
    "\n",
    "preexisting_mutations  = {}\n",
    "preexisting_mutations_genes = {}\n",
    "\n",
    "for ancestor in ancestral_mutations.keys():\n",
    "    this_anc = snps[snps['ancestor']==ancestor]\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_mutations = []\n",
    "    for info in this_anc['all_information'].values:\n",
    "        all_mutations += list([':'.join(x.split(':')[:-1]) for x in info.split('~')])\n",
    "        \n",
    "    muts,counts = np.unique(all_mutations,return_counts=True)\n",
    "    pre_ix = np.where(counts>cutoff)[0]\n",
    "    \n",
    "    \n",
    "    preexisting_mutations[ancestor] = [mut for mut in muts[pre_ix] if ':' in mut]\n",
    "    preexisting_mutations_genes[ancestor] = []\n",
    "    for m,mut in enumerate(muts[pre_ix]):\n",
    "        if ':' in mut:\n",
    "            split = mut.split(':')\n",
    "            preexisting_mutations_genes[ancestor].append(f'{split[4]}:{split[5]}({counts[pre_ix][m]})')\n",
    "            \n",
    "preexisting_mutations_genes['WT'] = []\n",
    "preexisting_mutations['WT'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04cde0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IRA1_NON': ['II:522427:A:T:IRA1:stop_gained:c.4202T>A:p.Leu1401*',\n",
       "  'V:510499:G:C:PAB1:missense_variant:c.127G>C:p.Gly43Arg',\n",
       "  'VI:101127:T:A:YFL021C-A:upstream_gene_variant:c.-4512A>T:nan',\n",
       "  'VII:1023358:C:A:YGR266W:missense_variant:c.703C>A:p.Gln235Lys',\n",
       "  'VII:161471:G:C:ATG1:missense_variant:c.1407G>C:p.Leu469Phe',\n",
       "  'VIII:269744:G:C:KSP1:stop_gained:c.1805C>G:p.Ser602*',\n",
       "  'VIII:270738:C:T:KSP1:missense_variant:c.811G>A:p.Asp271Asn',\n",
       "  'XII:1029498:C:A:RPL6B:synonymous_variant:c.261C>A:p.Thr87Thr',\n",
       "  'XII:122900:AT:A:PUF3:frameshift_variant:c.1814delA:p.Asn605fs',\n",
       "  'XII:123802:AG:A:PUF3:frameshift_variant:c.912delC:p.Tyr305fs',\n",
       "  'XII:123802:AG:AGG:PUF3:frameshift_variant:c.911dupC:p.Tyr305fs',\n",
       "  'XIV:204739:G:A:KEX2:missense_variant:c.2312G>A:p.Ser771Asn',\n",
       "  'XIV:218512:G:A:ELA1:synonymous_variant:c.151C>T:p.Leu51Leu',\n",
       "  'XV:608680:G:T:SPP2:missense_variant:c.518C>A:p.Thr173Lys',\n",
       "  'XV:818647:T:G:RPT4:upstream_gene_variant:c.-4939A>C:nan'],\n",
       " 'IRA1_MIS': ['II:522697:G:A:IRA1:missense_variant:c.3932C>T:p.Ala1311Val',\n",
       "  'V:142941:CAAT:C:MIT1:disruptive_inframe_deletion:c.1083_1085delTAA:p.Asn362del',\n",
       "  'V:177308:C:A:YER010C:upstream_gene_variant:c.-3970G>T:nan',\n",
       "  'V:303524:AT:ATT:TDA2:upstream_gene_variant:c.-1199_-1198insA:nan',\n",
       "  'XI:347074:C:T:YKL050C:upstream_gene_variant:c.-1454G>A:nan',\n",
       "  'XIV:467219:A:G:MKT1:missense_variant:c.89A>G:p.Asp30Gly',\n",
       "  'XIV:467219:A:T:MKT1:missense_variant:c.89A>T:p.Asp30Val',\n",
       "  'XIV:631356:ACACAAAAGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAG:A:YNR001W-A:frameshift_variant:c.102_183delGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAGCACAAAA:p.Tyr35fs',\n",
       "  'XV:87280:AT:A:MDH2:upstream_gene_variant:c.-4361delA:nan'],\n",
       " 'CYR1': ['II:610499:A:T:MED8:upstream_gene_variant:c.-746T>A:nan',\n",
       "  'X:427906:C:A:CYR1:missense_variant:c.2750C>A:p.Ser917Tyr',\n",
       "  'X:464355:T:TTA:YJR011C:upstream_gene_variant:c.-4930_-4929insTA:nan',\n",
       "  'XII:196744:T:A:UBR2:upstream_gene_variant:c.-3463A>T:nan',\n",
       "  'XVI:940751:T:G:ARR3:missense_variant:c.830T>G:p.Ile277Ser'],\n",
       " 'GPB2': ['I:40104:T:G:GPB2:stop_gained:c.846T>G:p.Tyr282*',\n",
       "  'IV:1170535:C:T:PAL1:missense_variant:c.1291G>A:p.Val431Ile',\n",
       "  'VI:101127:T:A:YFL021C-A:upstream_gene_variant:c.-4512A>T:nan',\n",
       "  'VI:58065:C:A:ACT1:upstream_gene_variant:c.-3369G>T:nan'],\n",
       " 'TOR1': ['VII:961959:T:G:YGR235C:missense_variant:c.103A>C:p.Asn35His',\n",
       "  'VIII:362075:C:A:tF(GAA)H2:upstream_gene_variant:c.-3506G>T:nan',\n",
       "  'X:393675:TTA:TTATA:VPS53:upstream_gene_variant:c.-2825_-2824insTA:nan',\n",
       "  'X:464355:T:TTA:YJR011C:upstream_gene_variant:c.-4930_-4929insTA:nan',\n",
       "  'X:564551:T:G:TOR1:missense_variant:c.5136T>G:p.Phe1712Leu',\n",
       "  'XIV:103969:A:G:MRPL10:missense_variant:c.134T>C:p.Phe45Ser',\n",
       "  'XIV:553379:C:G:COG6:upstream_gene_variant:c.-1392G>C:nan'],\n",
       " 'WT': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preexisting_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb72a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are recurrent mutations in putatively adaptive genes. As such, we want to consider these.\n",
    "# In addition, \n",
    "\n",
    "preexisting_to_ignore = {'IRA1_NON':['VIII:269744:G:C:KSP1:stop_gained:c.1805C>G:p.Ser602*',\n",
    "                                     'VIII:270738:C:T:KSP1:missense_variant:c.811G>A:p.Asp271Asn',\n",
    "                                      'V:510499:G:C:PAB1:missense_variant:c.127G>C:p.Gly43Arg',\n",
    "                                      'XII:122900:AT:A:PUF3:frameshift_variant:c.1814delA:p.Asn605fs',\n",
    "                                      'XII:123802:AG:A:PUF3:frameshift_variant:c.912delC:p.Tyr305fs',\n",
    "                                      'XII:123802:AG:AGG:PUF3:frameshift_variant:c.911dupC:p.Tyr305fs'],\n",
    "                         'IRA1_MIS':['V:142941:CAAT:C:MIT1:disruptive_inframe_deletion:c.1083_1085delTAA:p.Asn362del',\n",
    "                                     'XIV:467219:A:G:MKT1:missense_variant:c.89A>G:p.Asp30Gly',\n",
    "                                      'XIV:467219:A:T:MKT1:missense_variant:c.89A>T:p.Asp30Val',\n",
    "                                    'XIV:631356:ACACAAAAGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAG:A:CIT1:upstream_gene_variant:c.-377_-296delCTAAAAGGCGTCACGTTTTTTTCCGCCGCAGCCGCCCGGAAATGAAAAGTATGACCCCCGCTAGACCAAAAATACTTTTGTG:nan',\n",
    "                                    'V:303524:AT:ATT:TDA2:upstream_gene_variant:c.-1199_-1198insA'],\n",
    "                         'CYR1':[],\n",
    "                         'GPB2':[],\n",
    "                         'TOR1':['X:179445:C:A:PBS2:NON_SYNONYMOUS_CODING:cGt/cTt:R220L']\n",
    "                        }\n",
    "\n",
    "for ancestor,preexisting_list in preexisting_mutations.items():\n",
    "    preexisting_mutations[ancestor] = [mut for mut in preexisting_mutations[ancestor] if mut not in preexisting_to_ignore[ancestor]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1934bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_zygosity(call):\n",
    "    \n",
    "    if (call == '0/1') or (call == '0|1'):\n",
    "        return 'HET'\n",
    "    elif (call == '1/1') or (call == '1|1') or (call=='1'):\n",
    "        return 'HOM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96aa7c79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Manually reclassify a few mutants that are likely associated with something else\n",
    "\n",
    "mutants_to_reclassify = {'VI:101127:T:A:YFL021C-A:upstream_gene_variant:c.-4512A>T:nan':\n",
    " 'VI:101127:T:A:LPD1:downstream_gene_variant:c.*501A>T:nan', ## closer \"named\" gene, consistency with Aggeli 2021\n",
    " \n",
    " ### appears to be upstream modifier of CIT1\n",
    " 'XIV:631356:ACACAAAAGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAG:A:YNR001W-A:frameshift_variant:c.102_183delGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAGCACAAAA:p.Tyr35fs':\n",
    " 'XIV:631356:ACACAAAAGTATTTTTGGTCTAGCGGGGGTCATACTTTTCATTTCCGGGCGGCTGCGGCGGAAAAAAACGTGACGCCTTTTAG:A:CIT1:upstream_gene_variant:c.-377_-296delCTAAAAGGCGTCACGTTTTTTTCCGCCGCAGCCGCCCGGAAATGAAAAGTATGACCCCCGCTAGACCAAAAATACTTTTGTG:nan',\n",
    " \n",
    "### also appears to be upstream modifier of CIT1\n",
    "'XIV:631351:C:T:YNR001W-A:missense_variant:c.89C>T:p.Pro30Leu':\n",
    "'XIV:631351:C:T:CIT1:upstream_gene_variant:c.-290G>A:nan',\n",
    " \n",
    " ### others of question: RPL7, PET8? both downstream of CIT1...\n",
    "                         \n",
    "                         \n",
    " ### appears to be upstream modifier of ALD5\n",
    "    'V:303524:AT:ATT:TDA2:upstream_gene_variant:c.-1199_-1198insA:nan':\n",
    "    'V:303524:AT:ATT:ALD5:upstream_gene_variant:c.-505_-504insT:nan',\n",
    "                         \n",
    "    'V:303524:AT:A:TDA2:upstream_gene_variant:c.-1198delA:nan':\n",
    "    'V:303524:AT:A:ALD5:upstream_gene_variant:c.-505delT:nan',\n",
    "}\n",
    "\n",
    "new_muts = []\n",
    "new_info = []\n",
    "for muts,info in zip(snps['mutations'].values,snps['all_information'].values):\n",
    "    info_here = copy(info)\n",
    "    for original,new in mutants_to_reclassify.items():\n",
    "        if original in info:\n",
    "            info_here = copy(info.replace(original,new))\n",
    "\n",
    "    muts_here = []\n",
    "    for variant in info_here.split('~'):\n",
    "        split = variant.split(':')\n",
    "        muts_here.append(f'{split[4]}:{split[5]}:{mutation_zygosity(split[-1])}')      \n",
    "            \n",
    "    new_info.append(info_here)\n",
    "    new_muts.append(copy(muts_here))\n",
    "            \n",
    "                    \n",
    "snps['mutations'] = new_muts\n",
    "snps['all_information'] = new_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1bb946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       EvolvingFront_Sequencing_Plate1-A1\n",
      "1       EvolvingFront_Sequencing_Plate1-A2\n",
      "2       EvolvingFront_Sequencing_Plate1-A3\n",
      "3       EvolvingFront_Sequencing_Plate5-A1\n",
      "4       EvolvingFront_Sequencing_Plate1-A5\n",
      "                      ...                 \n",
      "343     EvolvingFront_Sequencing_Plate4-E8\n",
      "344     EvolvingFront_Sequencing_Plate4-E9\n",
      "345    EvolvingFront_Sequencing_Plate4-E10\n",
      "0      EvolvingFront_Sequencing_Plate4-E11\n",
      "1      EvolvingFront_Sequencing_Plate4-E12\n",
      "Name: destination_well, Length: 348, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ploidy_calls = p.read_csv(f'{home_dir}/data/BenomylTest/EvolvingFront_rearray_map_with_ploidy.csv')\n",
    "wgs_identified_barcodes = p.read_csv(f'{home_dir}/data/WGS/intermediate_files/EvolvingFront_WGS_allExtractedBCs.csv')\n",
    "sequencing_map = p.read_csv(f'{home_dir}/data/WGS/intermediate_files/sequencing_maps/EvolvingFront_Sequencing_list.csv')\n",
    "plate5_map = p.read_csv(f'{home_dir}/data/WGS/intermediate_files/EvolvingFront_WGS_Plate5_map.csv')\n",
    "\n",
    "additions = p.DataFrame([['EVO3D_TCG_rearray_Plate1-G11','EvolvingFront_Sequencing_Plate4-E11','CCGCCAATCCCGAACCCCGTTTCGCC_TATGCAAGACACAACATGCTTTTAAT'],\n",
    "                                       ['EVO3D_TCG_rearray_Plate1-G12','EvolvingFront_Sequencing_Plate4-E12','GACAGAAAAGCCAAATGGATTTACCG_AGCATAATAGCTAAGAGTATTTACTA']],\n",
    "                                      columns=['source_well','destination_well','barcode'])\n",
    "\n",
    "sequencing_map = p.concat([sequencing_map,additions])\n",
    "\n",
    "### replace sequencing samples with Plate5 instead of old name\n",
    "new_dest_wells = []\n",
    "for old_plate in sequencing_map['destination_well'].values:\n",
    "    old_name = old_plate.replace('EvolvingFront_Sequencing_','')\n",
    "    if old_name in plate5_map['oldplate_name'].values:\n",
    "        new_name = plate5_map[plate5_map['oldplate_name']==old_name]['Well'].values[0]\n",
    "        new_dest_wells.append(f'EvolvingFront_Sequencing_{new_name}')\n",
    "#         print(old_name,new_name)\n",
    "    else:\n",
    "        new_dest_wells.append(f'EvolvingFront_Sequencing_{old_name}')\n",
    "sequencing_map['destination_well'] = new_dest_wells\n",
    "\n",
    "print(sequencing_map['destination_well'])\n",
    "\n",
    "dests_renamed = []\n",
    "for plate in sequencing_map['destination_well'].values:\n",
    "    prefix = plate.split('-')[0]\n",
    "    row = plate.split('-')[1][0]\n",
    "    col = plate.split('-')[1][1:]\n",
    "    \n",
    "#     print(prefix,row,col)\n",
    "    dests_renamed.append(f\"{prefix.replace('Sequencing','WGS')}_{row}{int(col):02}\")\n",
    "sequencing_map['destination_well_renamed'] = dests_renamed\n",
    "\n",
    "\n",
    "source_names = []\n",
    "intended_bcs = []\n",
    "oriented_barcodes = []\n",
    "\n",
    "files_for_removal = []\n",
    "\n",
    "for entry,barcode in zip(wgs_identified_barcodes['file_prefix'].values,wgs_identified_barcodes['doubleBC'].values):\n",
    "    \n",
    "    if 'rearray' in entry:\n",
    "#         source_well = \n",
    "        \n",
    "        source_names.append(entry)\n",
    "        intended_bcs.append(ploidy_calls[ploidy_calls['destination_well']==entry]['barcode'].values[0])\n",
    "        oriented_barcodes.append(f\"{barcode.split('_')[1]}_{barcode.split('_')[0]}\")\n",
    "    else:\n",
    "        if entry in sequencing_map['destination_well_renamed'].values:\n",
    "            source_well = sequencing_map[sequencing_map['destination_well_renamed']==entry]['source_well'].values[0] \n",
    "            source_names.append(source_well)\n",
    "\n",
    "            intended_bcs.append(sequencing_map[sequencing_map['destination_well_renamed']==entry]['barcode'].values[0])\n",
    "            oriented_barcodes.append(f\"{barcode.split('_')[1]}_{barcode.split('_')[0]}\")\n",
    "        else:\n",
    "#             print(entry)\n",
    "            files_for_removal.append(entry)\n",
    "            \n",
    "wgs_identified_barcodes = wgs_identified_barcodes[~wgs_identified_barcodes['file_prefix'].isin(files_for_removal)]\n",
    "            \n",
    "wgs_identified_barcodes['source_name'] = source_names\n",
    "wgs_identified_barcodes['intendedBC'] = intended_bcs\n",
    "wgs_identified_barcodes['observedBC'] = oriented_barcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d71d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs_identified_barcodes.to_csv(f'{home_dir}/data/WGS/intermediate_files/EvolvingFront_WGS_IdentifiedBarcodes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bd10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps['file_prefix'] = snps['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "025ea47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps_plus_bcs = p.merge(wgs_identified_barcodes,snps,on='file_prefix')\n",
    "\n",
    "# new column without ancestral mutations (+ call ancestral mutations??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68474c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutations_in_ancestor = {}\n",
    "\n",
    "# for ancestor in list(ancestral_mutations.keys()):\n",
    "#     this_anc = snps_plus_bcs[snps_plus_bcs['ancestor']==ancestor]\n",
    "    \n",
    "#     mutations_here = []\n",
    "    \n",
    "#     for info in this_anc['all_information'].values:\n",
    "#         mutations_here += info.split('~')\n",
    "        \n",
    "#     unique_mutations,unique_counts = np.unique(mutations_here,return_counts=True)\n",
    "    \n",
    "#     multi_muts = unique_mutations[np.where(unique_counts>1)[0]]\n",
    "#     multi_counts = unique_counts[np.where(unique_counts>1)[0]]\n",
    "    \n",
    "#     for mut,count in zip(multi_muts[np.argsort(multi_counts)[::-1]],multi_counts[np.argsort(multi_counts)[::-1]]):\n",
    "#         print('\\n')\n",
    "#         print(mut,count)\n",
    "#         for (sample,bc,mutations,info) in zip(this_anc['sample'].values,this_anc['observedBC'].values,\n",
    "#                                           this_anc['mutations'].values,this_anc['all_information'].values):\n",
    "#             if mut in info:\n",
    "#                 print(sample,bc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eb747d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING MISMATCH! EVO3D_IRA1_NON_rearray_Plate2-C12 EvolvingFront_WGS_Plate4_B02 ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT ATCACAATAACTAAACTGATTCTTCA_GAATTAATTAGAAAGGGGATTAAGCG\n",
      "REMOVING MISMATCH! EVO3D_IRA1_NON_rearray_Plate2-D8 EvolvingFront_WGS_Plate4_B03 ATCACAATAACTAAACTGATTCTTCA_TAGTAAATCTCGAAAAAATTTACAAT ATCACAATAACTAAACTGATTCTTCA_TTTTAAATGACTAAGTAAATTCTCCT\n",
      "324 2 35 361\n"
     ]
    }
   ],
   "source": [
    "matches = 0\n",
    "mismatches = 0\n",
    "no_bc = 0\n",
    "\n",
    "mismatch_list = []\n",
    "\n",
    "for source,seq_name,intended,observed in wgs_identified_barcodes[['source_name','file_prefix','intendedBC','observedBC']].values:\n",
    "    if observed != '_':\n",
    "        if intended != observed:\n",
    "            print('REMOVING MISMATCH!',source,seq_name,intended,observed)\n",
    "            \n",
    "            mismatch_list.append(intended)\n",
    "            mismatches += 1\n",
    "        else:\n",
    "            matches += 1\n",
    "    else: \n",
    "        no_bc += 1\n",
    "#         print('\\t','no bc',seq_name,intended)\n",
    "        \n",
    "print(matches,mismatches,no_bc,matches+mismatches+no_bc)\n",
    "\n",
    "wgs_identified_barcodes = wgs_identified_barcodes[~wgs_identified_barcodes['intendedBC'].isin(mismatch_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18632bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Fit1D-2%','Fit1D-5%',\n",
    "              'Fit2D-2%','Fit2D-5%',\n",
    "              'Fit3D-2%','Fit3D-5%',\n",
    "              'Fit5D-2%','Fit5D-5%']\n",
    "\n",
    "# replicates = [1,2,3]\n",
    "replicates = {'Fit1D-2%':[1,2],\n",
    "              'Fit1D-5%':[1,2],\n",
    "              'Fit2D-2%':[1,2],\n",
    "              'Fit2D-5%':[1,2],\n",
    "              'Fit3D-2%':[1,2,3],\n",
    "              'Fit3D-5%':[1,2,3],\n",
    "              'Fit5D-2%':[1,2,3],\n",
    "              'Fit5D-5%':[1,2,3]}\n",
    "\n",
    "timepoints = {'Fit1D-2%':7,\n",
    "              'Fit1D-5%':7,\n",
    "              'Fit2D-2%':7,\n",
    "              'Fit2D-5%':7,\n",
    "              'Fit3D-2%':3,\n",
    "              'Fit3D-5%':3,\n",
    "              'Fit5D-2%':3,\n",
    "              'Fit5D-5%':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fab4d4a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/site-packages/pandas/compat/_optional.py:142\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m merged_fitness \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhome_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/EvolvingFront_2%5%FitnessMeasurementData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m time_fitness \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhome_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/EvolvingFront_2%5%FitnessMeasurementData_fitnessByTime.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m aggeli_variants \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mhome_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data/WGS/Aggeli_et_al_2021/GWS_Fit.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVariants\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m aggeli_commonvariants \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhome_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/WGS/Aggeli_et_al_2021/GWS_Fit.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m,sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommonVariants\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/site-packages/pandas/io/excel/_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/site-packages/pandas/io/excel/_base.py:1513\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1513\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:548\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    536\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m    537\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    538\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[0;32m~/miniforge3/envs/evolvingfront-env/lib/python3.11/site-packages/pandas/compat/_optional.py:145\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "merged_fitness = p.read_csv(f'{home_dir}/data/EvolvingFront_2%5%FitnessMeasurementData.csv')\n",
    "time_fitness = p.read_csv(f'{home_dir}/data/EvolvingFront_2%5%FitnessMeasurementData_fitnessByTime.csv')\n",
    "aggeli_variants = p.read_excel(f'{home_dir}/data/WGS/Aggeli_et_al_2021/GWS_Fit.xlsx',sheet_name='Variants')\n",
    "aggeli_commonvariants = p.read_excel(f'{home_dir}/data/WGS/Aggeli_et_al_2021/GWS_Fit.xlsx',sheet_name='CommonVariants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e6481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cloneID_list = []\n",
    "full_ploidy_list = []\n",
    "evo_cond_list = []\n",
    "anc_list = []\n",
    "mutation_list = []\n",
    "mutation_list_verbose = []\n",
    "\n",
    "for barcode,cloneID,source,ploidy,evo_cond,anc,gene,mut_type,additional_muts in zip(merged_fitness['barcode'].values,\n",
    "                                         merged_fitness['cloneID'].values,\n",
    "                                         merged_fitness['source_publication'].values,\n",
    "                                         merged_fitness['ploidy'].values,\n",
    "                                         merged_fitness['evolution_condition'].values,\n",
    "                                         merged_fitness['ancestor'].values,\n",
    "                                         merged_fitness['gene'].values,\n",
    "                                         merged_fitness['type'].values,\n",
    "                                         merged_fitness['additional_muts'].values):\n",
    "    if source == 'This_study':\n",
    "        \n",
    "        this_bc = ploidy_calls[ploidy_calls['barcode']==barcode]\n",
    "        this_id = np.nan\n",
    "        if len(this_bc) == 0:\n",
    "            this_id = np.nan\n",
    "            full_cloneID_list.append(np.nan)\n",
    "            full_ploidy_list.append('?')\n",
    "#             mutation_list.append(np.nan)\n",
    "        elif len(this_bc) > 1:\n",
    "#             print('hmm... more that one found')\n",
    "#             print(this_bc)\n",
    "            full_cloneID_list.append(this_bc['destination_well'].values[0])\n",
    "            full_ploidy_list.append(this_bc['ploidy'].values[0])\n",
    "            this_id = this_bc['destination_well'].values[0]\n",
    "            \n",
    "        else:\n",
    "            full_cloneID_list.append(this_bc['destination_well'].values[0])\n",
    "            full_ploidy_list.append(this_bc['ploidy'].values[0])\n",
    "            this_id = this_bc['destination_well'].values[0]\n",
    "            \n",
    "\n",
    "        bc_low_complexity = barcode.split('_')[0]\n",
    "        \n",
    "        entry = tools.new_lowcomplexity_bc_to_entry_dict[bc_low_complexity]\n",
    "        \n",
    "        if 'IRA1_NON' in entry:\n",
    "            anc_list.append('IRA1_NON')\n",
    "        elif 'IRA1_MIS' in entry:\n",
    "            anc_list.append('IRA1_MIS')\n",
    "        elif entry in ['TOR1','CYR1','GPB2']:\n",
    "            anc_list.append(entry)\n",
    "            entry = this_id\n",
    "            \n",
    "        if not p.isnull(entry):\n",
    "            if 'EVO1D' in entry:\n",
    "                evo_cond_list.append('Evo1D')\n",
    "            elif 'EVO2D' in entry:\n",
    "                evo_cond_list.append('Evo2D')\n",
    "            elif 'EVO3D' in entry:\n",
    "                evo_cond_list.append('Evo3D')\n",
    "            else:\n",
    "                evo_cond_list.append('unknown')\n",
    "        else:\n",
    "            evo_cond_list.append('unknown')\n",
    "        if this_id in sequencing_map['source_well'].values:\n",
    "\n",
    "            seq_well = sequencing_map[sequencing_map['source_well']==this_id]['destination_well_renamed'].values[0]\n",
    "            if seq_well in snps['sample'].values:\n",
    "#                 mutation_list.append(str(snps[snps['sample']==seq_well]['mutations'].values[0]))\n",
    "                mutation_list_verbose.append(str(snps[snps['sample']==seq_well]['all_information'].values[0]))\n",
    "                \n",
    "                variants = str(snps[snps['sample']==seq_well]['all_information'].values[0]).split('~')\n",
    "                muts_here = []\n",
    "                for variant in variants:\n",
    "                    split = variant.split(':')\n",
    "                    muts_here.append(f'{split[4]}:{split[5]}:{mutation_zygosity(split[-1])}')      \n",
    "            \n",
    "                mutation_list.append(muts_here)\n",
    "                \n",
    "            elif this_id in snps['sample'].values:\n",
    "                mutation_list_verbose.append(snps[snps['sample']==this_id]['all_information'].values[0])\n",
    "\n",
    "                variants = str(snps[snps['sample']==this_id]['all_information'].values[0]).split('~')\n",
    "                muts_here = []\n",
    "                for variant in variants:\n",
    "                    split = variant.split(':')\n",
    "                    muts_here.append(f'{split[4]}:{split[5]}:{mutation_zygosity(split[-1])}')  \n",
    "                    \n",
    "                mutation_list.append(muts_here)\n",
    "                \n",
    "            else:\n",
    "                mutation_list.append(np.nan)\n",
    "                mutation_list_verbose.append(np.nan)\n",
    "        else:\n",
    "            mutation_list.append(np.nan)\n",
    "            mutation_list_verbose.append(np.nan)\n",
    "    \n",
    "    elif source == 'Aggeli2020':\n",
    "        full_cloneID_list.append(cloneID)\n",
    "        full_ploidy_list.append(ploidy)\n",
    "        evo_cond_list.append(evo_cond)\n",
    "        anc_list.append(anc)\n",
    "        \n",
    "        this_calls = aggeli_variants[aggeli_variants['low_high']==barcode]\n",
    "        this_common_calls = aggeli_commonvariants[aggeli_commonvariants['GWS_Bar']==barcode]\n",
    "        \n",
    "        variants = []\n",
    "        \n",
    "        for entries in this_calls[['CHROM','POS','REF','ALT','GENE','EFFECT','CODON_CHANGE','AMINO_ACID_CHANGE','GT']].values:\n",
    "            variants.append(':'.join([str(x) for x in entries]))\n",
    "        for entries in this_common_calls[['CHROM','POS','REF','ALT','GENE','EFFECT','CODON_CHANGE','AMINO_ACID_CHANGE','GT']].values:\n",
    "            variants.append(':'.join([str(x) for x in entries]))  \n",
    "            \n",
    "        variants = list(np.unique(variants))\n",
    "        \n",
    "        if len(variants) > 0: \n",
    "            mutation_list_verbose.append('~'.join(variants))\n",
    "            muts_here = []\n",
    "            for variant in variants:\n",
    "                split = variant.split(':')\n",
    "                muts_here.append(f'{split[4]}:{split[5]}:{mutation_zygosity(split[-1])}')      \n",
    "            \n",
    "            mutation_list.append(muts_here)\n",
    "            \n",
    "        elif gene not in [np.nan,'None','NotSequenced','other']:\n",
    "            mutation_list.append(f'{gene}-{mut_type}; {additional_muts}')\n",
    "            mutation_list_verbose.append(np.nan)\n",
    "        elif not p.isnull(gene):\n",
    "            mutation_list.append(f'{additional_muts}')\n",
    "            mutation_list_verbose.append(np.nan)\n",
    "        else:\n",
    "            mutation_list.append(np.nan)\n",
    "            mutation_list_verbose.append(np.nan)\n",
    "    \n",
    "    \n",
    "    \n",
    "    else:\n",
    "\n",
    "        full_cloneID_list.append(cloneID)\n",
    "        full_ploidy_list.append(ploidy)\n",
    "        evo_cond_list.append(evo_cond)\n",
    "        anc_list.append(anc)\n",
    "        mutation_list_verbose.append(np.nan)\n",
    "        if gene not in [np.nan,'None','NotSequenced','other']:\n",
    "            mutation_list.append(f'{gene}-{mut_type}; {additional_muts}')\n",
    "        elif not p.isnull(gene):\n",
    "            mutation_list.append(f'{additional_muts}')\n",
    "        else:\n",
    "            mutation_list.append(np.nan)\n",
    "        \n",
    "merged_fitness['cloneID_new'] = full_cloneID_list\n",
    "merged_fitness['ploidy_new'] = full_ploidy_list\n",
    "merged_fitness['evolution_condition'] = evo_cond_list\n",
    "merged_fitness['ancestor'] = anc_list\n",
    "merged_fitness['all_mutations'] = mutation_list\n",
    "merged_fitness['all_mutations_verbose'] = mutation_list_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add some Aggeli mutants to pre-existing list\n",
    "preexisting_mutations['GPB2'].append('I:40104:T:G:GPB2:STOP_GAINED:taT/taG:Y282*') # ancestral \n",
    "preexisting_mutations['GPB2'].append('VI:101127:T:A:LPD1:DOWNSTREAM:501:nan')\n",
    "preexisting_mutations['GPB2'].append('VI:58065:C:A:TUB2:DOWNSTREAM:356:nan')\n",
    "preexisting_mutations['GPB2'].append('IV:1170535:C:T:YDR348C:NON_SYNONYMOUS_CODING:Gtt/Att:V431I')\n",
    "\n",
    "preexisting_mutations['CYR1'].append('X:427906:C:A:CYR1:NON_SYNONYMOUS_CODING:tCt/tAt:S917Y') # ancestral\n",
    "preexisting_mutations['CYR1'].append('XVI:940751:T:G:ARR3:NON_SYNONYMOUS_CODING:aTt/aGt:I277S')\n",
    "preexisting_mutations['CYR1'].append('II:632333:G:C:LDH1:NON_SYNONYMOUS_CODING:tCt/tGt:S350C')\n",
    "preexisting_mutations['CYR1'].append('XIII:23476:G:GA:PHO84:DOWNSTREAM:560:nan')\n",
    "\n",
    "preexisting_mutations['TOR1'].append('X:564551:T:G:TOR1:NON_SYNONYMOUS_CODING:ttT/ttG:F1712L') # ancestral\n",
    "preexisting_mutations['TOR1'].append('VIII:362075:C:A:FUR1:UPSTREAM:40:nan')\n",
    "preexisting_mutations['TOR1'].append('XIV:103969:A:G:MRPL10:NON_SYNONYMOUS_CODING:tTc/tCc:F45S')\n",
    "preexisting_mutations['TOR1'].append('VII:961959:T:G:MOS2:NON_SYNONYMOUS_CODING:Aat/Cat:N35H')\n",
    "preexisting_mutations['TOR1'].append('XIV:553379:C:G:YNL040W:UPSTREAM:1:nan')\n",
    "preexisting_mutations['TOR1'].append('X:179445:C:A:PBS2:NON_SYNONYMOUS_CODING:cGt/cTt:R220L')\n",
    "\n",
    "for anc,muts in preexisting_mutations.items():\n",
    "    new_list = []\n",
    "    for mut in muts:\n",
    "        for original,new in mutants_to_reclassify.items():\n",
    "            if original in mut:\n",
    "                new_list.append(mut.replace(original,new))\n",
    "                break\n",
    "        else:\n",
    "            new_list.append(mut)\n",
    "    preexisting_mutations[anc] = new_list  \n",
    "    \n",
    "for ancestor,preexisting_list in preexisting_mutations.items():\n",
    "    preexisting_mutations[ancestor] = [mut for mut in preexisting_mutations[ancestor] if mut not in preexisting_to_ignore[ancestor]]\n",
    "                \n",
    "with open(f'{home_dir}/data/intermediate/preexisting_mutations.pkl', 'wb') as f:\n",
    "    pickle.dump(preexisting_mutations, f)\n",
    "\n",
    "\n",
    "ancestral_mutations_aggeli_format = {'CYR1':'X:427906:C:A:CYR1:NON_SYNONYMOUS_CODING:tCt/tAt:S917Y',\n",
    "                                     'GPB2':'I:40104:T:G:GPB2:STOP_GAINED:taT/taG:Y282*',\n",
    "                                    'TOR1':'X:564551:T:G:TOR1:NON_SYNONYMOUS_CODING:ttT/ttG:F1712L',\n",
    "                                     'IRA1_MIS':'','IRA1_NON':''}\n",
    "# ancestral_mutations_aggeli['GPB2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d06050",
   "metadata": {},
   "outputs": [],
   "source": [
    "preexisting_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faeb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "### call putative causal genes, categorize them under \"gene\" organize other mutations\n",
    "\n",
    "gene_hits = {}\n",
    "gene_hits_samples = {}\n",
    "gene_hit_count = {}\n",
    "\n",
    "\n",
    "for ancestor in ancestral_mutations.keys():\n",
    "    this_anc = merged_fitness[merged_fitness['ancestor']==ancestor]\n",
    "    \n",
    "    gene_hits[ancestor] = {}\n",
    "    gene_hits_samples[ancestor] = {}\n",
    "\n",
    "    for mutations_verbose in this_anc['all_mutations_verbose'].values:\n",
    "        if not p.isnull(mutations_verbose):\n",
    "            variants = mutations_verbose.split('~')\n",
    "            genes_in_sample = []\n",
    "            for variant in variants:\n",
    "                for pre_existing in preexisting_mutations[ancestor]:\n",
    "                    if pre_existing in variant:\n",
    "                        break\n",
    "                else: # if it's not a pre-existing mutation\n",
    "                    gene = variant.split(':')[4]\n",
    "                    if gene not in genes_in_sample:\n",
    "                        if gene not in gene_hits[ancestor]:\n",
    "                            gene_hits[ancestor][gene] = [variant]\n",
    "                            gene_hits_samples[ancestor][gene] = [sample]\n",
    "                        else:\n",
    "                            if variant not in gene_hits[ancestor][gene]:\n",
    "                                gene_hits[ancestor][gene].append(variant)\n",
    "                                gene_hits_samples[ancestor][gene].append(sample)\n",
    "                        genes_in_sample.append(gene)\n",
    "\n",
    "    gene_hit_count[ancestor] = {gene:len(effects) for gene,effects in gene_hits[ancestor].items()}                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d14dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_hit_anc_df = p.DataFrame(columns=['ancestor','gene','count','effects','samples'])\n",
    "\n",
    "gene_list = []\n",
    "count_list = []\n",
    "effect_list = []\n",
    "anc_list = []\n",
    "sample_list = []\n",
    "\n",
    "for ancestor in ancestral_mutations.keys():\n",
    "    gene_list += gene_hit_count[ancestor].keys()\n",
    "    count_list += (gene_hit_count[ancestor].values())\n",
    "    effect_list += gene_hits[ancestor].values()\n",
    "    anc_list += [ancestor] * len(gene_hit_count[ancestor].keys())\n",
    "    sample_list += gene_hits_samples[ancestor].values()\n",
    "\n",
    "gene_hit_anc_df['ancestor'] = anc_list\n",
    "gene_hit_anc_df['gene'] = gene_list\n",
    "gene_hit_anc_df['count'] =  count_list\n",
    "gene_hit_anc_df['effects'] = effect_list\n",
    "gene_hit_anc_df['samples'] = sample_list\n",
    "\n",
    "\n",
    "gene_hit_anc_df.to_csv(f'{home_dir}/data/WGS/intermediate_files/EvolvingFront_WGS_RepeatHitGenes_byAncestor.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee09532",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ancs = gene_hit_anc_df.groupby('gene',as_index=False).sum()\n",
    "\n",
    "sorted_all = all_ancs[all_ancs['count']>1].sort_values(['count','gene'],ascending=[False,True])\n",
    "# sorted_all = all_ancs.sort_values(['count','gene'],ascending=[False,True])\n",
    "\n",
    "count_matrix = np.zeros((len(ancestral_mutations.keys())+1,len(sorted_all)))\n",
    "\n",
    "count_matrix[0,:] = sorted_all['count'].values\n",
    "\n",
    "for a,ancestor in enumerate(ancestral_mutations.keys()):\n",
    "    for g,gene in enumerate(sorted_all['gene'].values):\n",
    "        this_gene_anc = gene_hit_anc_df[(gene_hit_anc_df['gene']==gene) & (gene_hit_anc_df['ancestor']==ancestor)]\n",
    "        if len(this_gene_anc) == 1:\n",
    "            count_matrix[a+1,g] = this_gene_anc['count'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,20))\n",
    "plt.pcolormesh(count_matrix[1:,:].swapaxes(0,1),cmap='Reds',vmin=0,vmax=15)\n",
    "plt.colorbar()\n",
    "# plt.cmap()\n",
    "# plt.yticks([x+0.5 for x in range(len(ancestral_mutations.keys())+1)],['All']+list(ancestral_mutations.keys()))\n",
    "plt.xticks([x+0.5 for x in range(len(ancestral_mutations.keys()))],[item.replace('_','\\n') for item in list(ancestral_mutations.keys())])\n",
    "plt.yticks([x+0.5 for x in range(len(sorted_all['gene'].values))],list(sorted_all['gene'].values))\n",
    "\n",
    "for a in range(len(ancestral_mutations.keys())):\n",
    "    for g in range(len(sorted_all['gene'].values)):\n",
    "        text_color='k'\n",
    "        if count_matrix[a+1,g] > 15:\n",
    "            text_color = 'w'\n",
    "        \n",
    "        plt.text(x=a+0.5,y=g+0.5,s=f'{int(count_matrix[a+1,g])}',ha='center',va='center',color=text_color)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.savefig(f'{home_dir}/figures/analysis/mutations/WGS_GeneHits_byAncestor_Matrix.pdf',bbox_inches='tight')\n",
    "# plt.savefig(f'{home_dir}/plots/WGS_GeneHits_byAncestor_Matrix.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3369a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's call genes with at least 3 unique mutations across all sequenced samples \"putatively causal\"\n",
    "\n",
    "putative_causal_genes = list(all_ancs[all_ancs['count']>=3].sort_values(['count','gene'],ascending=[False,True])['gene'].values)\n",
    "\n",
    "\n",
    "## \n",
    "\n",
    "manual_removal_genes = ['YGR283C']\n",
    "\n",
    "putative_causal_genes = [gene for gene in putative_causal_genes if gene not in manual_removal_genes]\n",
    "\n",
    "\n",
    "### manually add in some more genes, based on overlap of commonly hit pathways\n",
    "\n",
    "manual_putative_additions = [\n",
    "    'BMH1', # involved in RTG pathway\n",
    "    'BMH2', # involved in RTG pathway\n",
    "    'GPR1', # involved in Ras/PKA pathway\n",
    "    'PAN2', # involved in deadenylation, interacts with PAB1\n",
    "    'PAN3', # involved in deadenylation, interacts with PAB1\n",
    "    'SCH9',\n",
    "    'RAS2',\n",
    "    'YAK1',\n",
    "    'TFS1',\n",
    "    'GPB1',\n",
    "    'MDH2',\n",
    "    'HOG1',\n",
    "    'PBS2',\n",
    "    'MTH1', # related to glucose-senseing\n",
    "    \n",
    "]\n",
    "\n",
    "putative_causal_genes += manual_putative_additions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "causal_genes = []\n",
    "causal_effect = []\n",
    "other_genes = []\n",
    "for ancestor,gene,all_mutations_verbose,all_mutations in zip(merged_fitness['ancestor'].values,\n",
    "                                                             merged_fitness['gene'].values,\n",
    "                                                             merged_fitness['all_mutations_verbose'].values,\n",
    "                                                             merged_fitness['all_mutations'].values):\n",
    "    \n",
    "    if ancestor != 'WT':\n",
    "        this_causal = []\n",
    "        this_effect = []\n",
    "        this_other = []\n",
    "        if not p.isnull(all_mutations_verbose):\n",
    "            variants = all_mutations_verbose.split('~')\n",
    "            for variant in variants:\n",
    "                split = variant.split(':')\n",
    "                gene = split[4]\n",
    "                effect = split[5]\n",
    "                for pre in preexisting_mutations[ancestor]:\n",
    "                    if pre in variant:\n",
    "                        if (pre not in ancestral_mutations[ancestor]) and (pre not in ancestral_mutations_aggeli_format[ancestor]):\n",
    "                            this_other.append(f'{gene}-{effect}')\n",
    "                        break\n",
    "                else:\n",
    "                    if gene in putative_causal_genes:\n",
    "                        if gene not in this_causal:\n",
    "                            this_causal.append(gene)\n",
    "                            this_effect.append(effect)\n",
    "                        else:\n",
    "                            loc = np.where(np.isin(this_causal,gene))[0][0]\n",
    "                            this_effect[loc] = this_effect[loc]+effect\n",
    "                    else:\n",
    "                        this_other.append(f'{gene}-{effect}')\n",
    "\n",
    "            causal_genes.append('+'.join(this_causal))\n",
    "            causal_effect.append('+'.join(this_effect))\n",
    "            other_genes.append(this_other)\n",
    "        else:\n",
    "            causal_genes.append(np.nan)\n",
    "            causal_effect.append(np.nan)\n",
    "            other_genes.append(np.nan)\n",
    "                    \n",
    "     \n",
    "        \n",
    "    else:\n",
    "        causal_genes.append(gene)\n",
    "        causal_effect.append(np.nan)\n",
    "        other_genes.append(all_mutations)\n",
    "\n",
    "merged_fitness['gene'] = causal_genes\n",
    "merged_fitness['effect'] = causal_effect\n",
    "merged_fitness['other_genes'] = other_genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa665ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conditions = {'Fit1D_both2%5%':['Fit1D-2%','Fit1D-5%'],\n",
    "                 'Fit2D_both2%5%':['Fit2D-2%','Fit2D-5%'],\n",
    "                 'Fit3D_both2%5%':['Fit3D-2%','Fit3D-5%'],\n",
    "                 'Fit5D_both2%5%':['Fit5D-2%','Fit5D-5%']}\n",
    "\n",
    "\n",
    "for new_condition,old_conditions in new_conditions.items():\n",
    "    \n",
    "    new_fitness, new_error = tools.inverse_variance_mean(merged_fitness[[f'{condition}_fitness' for condition in old_conditions]].values,\n",
    "                                                   merged_fitness[[f'{condition}_error' for condition in old_conditions]].values)\n",
    "    \n",
    "    merged_fitness[f'{new_condition}_fitness'] = new_fitness\n",
    "    merged_fitness[f'{new_condition}_error'] = new_error\n",
    "    \n",
    "    new_fitness_li, new_error_li = tools.inverse_variance_mean(merged_fitness[[f'{condition}_fitness_Li2019Neutrals' for condition in old_conditions]].values,\n",
    "                                                   merged_fitness[[f'{condition}_error_Li2019Neutrals' for condition in old_conditions]].values)\n",
    "  \n",
    "    merged_fitness[f'{new_condition}_fitness_Li2019Neutrals'] = new_fitness_li\n",
    "        \n",
    "    merged_fitness[f'{new_condition}_error_Li2019Neutrals'] = new_error_li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea90ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_timepoints = [0]\n",
    "\n",
    "early_conditions = {'Fit2D':['Fit2D-2%_R1','Fit2D-2%_R2','Fit2D-5%_R1','Fit2D-5%_R2'],\n",
    "                    'Fit3D':['Fit3D-2%_R1','Fit3D-2%_R2','Fit3D-2%_R3','Fit3D-5%_R1','Fit3D-5%_R2','Fit3D-5%_R3'],\n",
    "                    'Fit5D':['Fit5D-2%_R1','Fit5D-2%_R2','Fit5D-2%_R3','Fit5D-5%_R1','Fit5D-5%_R2','Fit5D-5%_R3']\n",
    "                   }\n",
    "\n",
    "for condition,reps in early_conditions.items():\n",
    "    early_intervals = [f'{rep}_T{t}' for rep in reps for t in early_timepoints]\n",
    "    early_fitness,early_error = tools.inverse_variance_mean(time_fitness[early_intervals].values,\n",
    "                                                 time_fitness[[x+'_error' for x in early_intervals]].values)\n",
    "    \n",
    "\n",
    "    merged_fitness[f'{condition}_early_fitness'] = early_fitness\n",
    "    merged_fitness[f'{condition}_early_error'] = early_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d46b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness['Fit2D_early-Fit1D_both2%5%_fitness'] =  merged_fitness['Fit2D_early_fitness'] - merged_fitness['Fit1D_both2%5%_fitness']\n",
    "merged_fitness['Fit2D_early-Fit1D_both2%5%_error'] = merged_fitness['Fit2D_early_error'] + merged_fitness['Fit1D_both2%5%_error']\n",
    "\n",
    "merged_fitness['Fit5D_early-Fit3D_early_fitness'] =  (merged_fitness['Fit2D_early_fitness'] - merged_fitness['Fit1D_both2%5%_fitness'])/2\n",
    "merged_fitness['Fit5D_early-Fit3D_early_error'] = (merged_fitness['Fit2D_early_error'] + merged_fitness['Fit1D_both2%5%_error'])/(2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneday_vals_inorder = merged_fitness[[x+'_fitness' for x in np.random.permutation(oneday_options)]].values\n",
    "# twoday_vals_inorder = time_fitness[np.random.permutation(twoday_options)].values\n",
    "\n",
    "# resp_ests = (twoday_order.values-oneday_order.values)/24\n",
    "\n",
    "### Calculate Performances from early fitnesses\n",
    "\n",
    "# resp_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1','Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "resp_1Day = ['Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "# resp_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1']\n",
    "resp_2Day = ['Fit2D-2%_R1_T0','Fit2D-2%_R2_T0','Fit2D-5%_R1_T0','Fit2D-5%_R2_T0']\n",
    "\n",
    "resp_1Day_mean = tools.inverse_variance_mean(merged_fitness[[x+'_fitness' for x in resp_1Day]].values,\n",
    "                                            merged_fitness[[x+'_error' for x in resp_1Day]].values)\n",
    "resp_2Day_mean = tools.inverse_variance_mean(time_fitness[[x for x in resp_2Day]].values,\n",
    "                                            time_fitness[[x+'_error' for x in resp_2Day]].values)\n",
    "\n",
    "\n",
    "resp_ests = (resp_2Day_mean[0]-resp_1Day_mean[0])/24\n",
    "resp_err = np.sqrt((resp_2Day_mean[1]**2+resp_1Day_mean[1]**2)/(24**2))\n",
    "\n",
    "# ferm_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1','Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "ferm_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1']\n",
    "# ferm_1Day = ['Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "\n",
    "ferm_1Day_mean = tools.inverse_variance_mean(merged_fitness[[x+'_fitness' for x in ferm_1Day]].values,\n",
    "                                            merged_fitness[[x+'_error' for x in ferm_1Day]].values)\n",
    "\n",
    "ferm_ests = (ferm_1Day_mean[0]-4*resp_ests)/16\n",
    "ferm_err = np.sqrt((ferm_1Day_mean[1]**2+4**2*resp_err**2)/(16**2))\n",
    "\n",
    "\n",
    "stat_ests = (merged_fitness['Fit5D_early_fitness'].values-merged_fitness['Fit3D_early_fitness'].values)/48\n",
    "stat_err = np.sqrt((merged_fitness['Fit5D_early_error'].values**2+merged_fitness['Fit3D_early_error'].values**2)/(48**2))\n",
    "\n",
    "merged_fitness['ResPerHour'] = resp_ests\n",
    "merged_fitness['FerPerHour'] = ferm_ests\n",
    "merged_fitness['StaPerHour'] = stat_ests\n",
    "\n",
    "merged_fitness['ResPerHour_error'] = resp_err\n",
    "merged_fitness['FerPerHour_error'] = ferm_err\n",
    "merged_fitness['StaPerHour_error'] = stat_err\n",
    "\n",
    "### Calculate Performances from overall fitnesses\n",
    "               \n",
    "# resp_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1','Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "# # resp_1Day = ['Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "# # resp_2Day = ['Fit2D-2%_R1','Fit2D-2%_R2_T0','Fit2D-5%_R1_T0','Fit2D-5%_R2_T0']\n",
    "# resp_2Day = ['Fit2D-2%','Fit2D-5%']\n",
    "\n",
    "# resp_1Day_mean = tools.inverse_variance_mean(merged_fitness[[x+'_fitness' for x in resp_1Day]].values,\n",
    "#                                             merged_fitness[[x+'_error' for x in resp_1Day]].values)\n",
    "# resp_2Day_mean = tools.inverse_variance_mean(merged_fitness[[x+'_fitness' for x in resp_2Day]].values,\n",
    "#                                             merged_fitness[[x+'_error' for x in resp_2Day]].values)\n",
    "\n",
    "\n",
    "# resp_ests = (resp_2Day_mean[0]-resp_1Day_mean[0])/24\n",
    "# resp_err = np.sqrt((resp_2Day_mean[1]**2+resp_1Day_mean[1]**2)/(24**2))\n",
    "\n",
    "# ferm_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1','Fit1D-2%-R2','Fit1D-5%-R2']\n",
    "# # ferm_1Day = ['Fit1D-2%-R1','Fit1D-5%-R1']\n",
    "\n",
    "# ferm_1Day_mean = tools.inverse_variance_mean(merged_fitness[[x+'_fitness' for x in ferm_1Day]].values,\n",
    "#                                             merged_fitness[[x+'_error' for x in ferm_1Day]].values)\n",
    "\n",
    "# ferm_ests = (ferm_1Day_mean[0]-4*resp_ests)/16\n",
    "# ferm_err = np.sqrt((ferm_1Day_mean[1]**2+4**2*resp_err**2)/(16**2))\n",
    "\n",
    "# stat_ests = (merged_fitness['Fit5D_both2%5%_fitness'].values-merged_fitness['Fit3D_both2%5%_fitness'].values)/48\n",
    "# stat_err = np.sqrt((merged_fitness['Fit5D_both2%5%_error'].values**2+merged_fitness['Fit3D_both2%5%_error'].values**2)/(48**2))\n",
    "\n",
    "# merged_fitness['ResPerHour'] = resp_ests\n",
    "# merged_fitness['FerPerHour'] = ferm_ests\n",
    "# merged_fitness['StaPerHour'] = stat_ests\n",
    "\n",
    "# merged_fitness['ResPerHour_error'] = resp_err\n",
    "# merged_fitness['FerPerHour_error'] = ferm_err\n",
    "# merged_fitness['StaPerHour_error'] = stat_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(resp_1Day_mean[0],resp_1Day_mean[1]**2/resp_1Day_mean[0],alpha=0.1,label='resp1')\n",
    "plt.scatter(resp_2Day_mean[0],resp_2Day_mean[1]**2/resp_2Day_mean[0],alpha=0.1,label='resp2')\n",
    "plt.scatter(ferm_1Day_mean[0],ferm_1Day_mean[1]**2/ferm_1Day_mean[0],alpha=0.1,label='ferm1')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Fitness')\n",
    "plt.ylabel('Variance/Fitness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_2Day_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferm_1Day_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Are barcodes where evolution condition is unknown too noisy?\n",
    "\n",
    "plotting_conditions = ['Fit1D_both2%5%','Fit2D_early','Fit3D_early','Fit5D_early']\n",
    "plt.figure(figsize=(12,8))\n",
    "for c,condition in enumerate(plotting_conditions):\n",
    "    plt.subplot(2,2,c+1)\n",
    "    color_list = [matplotlib.colors.to_rgba('gray',0.1) if evo_cond != 'unknown' else matplotlib.colors.to_rgba('r',0.8)\n",
    "                  for evo_cond in merged_fitness['evolution_condition'].values]\n",
    "    \n",
    "    plt.scatter(merged_fitness[f'{condition}_fitness'],merged_fitness[f'{condition}_error'],c=color_list)\n",
    "#     plt.scatter(merged_fitness[f'{condition}_fitness'],np.abs(1.96*np.sqrt(merged_fitness[f'{condition}_error'])),c=color_list)\n",
    "    plt.xlabel(f'{condition}_fitness')\n",
    "    plt.ylabel(f'{condition}_error')\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    \n",
    "merged_fitness[merged_fitness['evolution_condition']=='unknown'][['barcode','all_mutations','source_publication','Fit1D-2%-T0','Fit5D-2%-T0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b51d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[merged_fitness['evolution_condition'].isin(['unknown'])].to_csv(f'{home_dir}/data/intermediate/mutants_excluded_unknown_condition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove mutants with unknown evolution condition\n",
    "\n",
    "merged_fitness = merged_fitness[~merged_fitness['evolution_condition'].isin(['unknown'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9990e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove false barcodes that are sequencing errors from true barcode\n",
    "\n",
    "seq_errors = {'TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTCATCA':[\n",
    "    'TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATGAATGGTATTTATCA',\n",
    "    'TGATCAATCTACAAAAATATTTAATG_GAGTGAAACATAAATGGTATTCATCA']}\n",
    "\n",
    "to_remove = tools.flatten(seq_errors.values())\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89934bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness = merged_fitness[~merged_fitness['barcode'].isin(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which other measurements are too noisy to be included?\n",
    "\n",
    "this_study = merged_fitness[merged_fitness['source_publication'].isin(['Venkataram2015','Aggeli2021','This_study'])]\n",
    "\n",
    "slope = (0.1-1.0)/3.5\n",
    "noisy_mutants = [barcode  for barcode,f,e in zip(this_study['barcode'].values,\n",
    "                                         this_study['Fit2D_early_fitness'].values,\n",
    "                                         this_study['Fit2D_early_error'].values) if e>f*slope+1.0]\n",
    "### Are barcodes where evolution condition is unknown too noisy?\n",
    "\n",
    "plotting_conditions = ['Fit1D_both2%5%','Fit2D_early','Fit3D_early','Fit5D_early']\n",
    "plt.figure(figsize=(12,8))\n",
    "for c,condition in enumerate(plotting_conditions):\n",
    "    plt.subplot(2,2,c+1)\n",
    "    color_list = [matplotlib.colors.to_rgba('gray',0.1) if evo_cond != 'unknown' else matplotlib.colors.to_rgba('r',0.8)\n",
    "                  for evo_cond in this_study['evolution_condition'].values]\n",
    "    \n",
    "    if condition == 'Fit2D_early':\n",
    "        plt.plot([0.0,3.5],[1.0,0.1],'k--')\n",
    "        \n",
    "    slope = (0.1-1.0)/3.5\n",
    "    color_list = [matplotlib.colors.to_rgba('gray',0.1) if e<f*slope+1.0 else 'r'\n",
    "                  for f,e in zip(this_study['Fit2D_early_fitness'].values,this_study['Fit2D_early_error'].values)]\n",
    "\n",
    "\n",
    "#     if condition == 'Fit1D_both2%5%':\n",
    "#         plt.plot([0.0,1.2],[0.4,0.05],'k--')\n",
    "        \n",
    "#     slope = (0.02-0.7)/1.4\n",
    "#     color_list = [matplotlib.colors.to_rgba('gray',0.1) if e<f*slope+0.7 else 'r'\n",
    "#                   for f,e in zip(this_study['Fit1D_both2%5%_fitness'].values,this_study['Fit1D_both2%5%_error'].values)]\n",
    "    \n",
    "    plt.scatter(this_study[f'{condition}_fitness'],this_study[f'{condition}_error'],c=color_list)\n",
    "#     plt.scatter(merged_fitness[f'{condition}_fitness'],np.abs(1.96*np.sqrt(merged_fitness[f'{condition}_error'])),c=color_list)\n",
    "    plt.xlabel(f'{condition}_fitness')\n",
    "    plt.ylabel(f'{condition}_error')\n",
    "    \n",
    "    \n",
    "#    plt.yscale('log')\n",
    "    \n",
    "# merged_fitness[merged_fitness['evolution_condition']=='unknown'][['barcode','all_mutations','source_publication','Fit1D-2%-T0','Fit5D-2%-T0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[merged_fitness['barcode'].isin(noisy_mutants)][['barcode','source_publication','ancestor','gene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness = merged_fitness[~merged_fitness['barcode'].isin(noisy_mutants)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_dist(fitness,error,centroid):\n",
    "    \n",
    "#     centroid_arr = \n",
    "    \n",
    "    z_score = (fitness-centroid)/np.std(error)\n",
    "    \n",
    "    return z_score\n",
    "    \n",
    "def cutoff_z_score(fitness,error,centroid,cutoff=2):\n",
    "    \n",
    "    z_scores = z_score_dist(fitness,error,centroid)\n",
    "    \n",
    "    return [True if np.all(np.abs(z)<cutoff) else False for z in z_scores]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce2502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class classification_set()\n",
    "\n",
    "def classify_mutants(prior_set,data,distance_metric='mahalanobis',cutoff=3,counter=0,counter_cutoff=10):\n",
    "    \n",
    "    set_centroid = np.nanmean(data[prior_set,:],axis=0)\n",
    "    set_covariance = np.cov(data[prior_set,:].swapaxes(0,1))\n",
    "    # dists = distance.cdist(this_anc[calling_conditions],[pure_diploid_centroid])\n",
    "    if distance_metric == 'mahalanobis':\n",
    "        dists = distance.cdist(this_anc[calling_conditions].values,[set_centroid],\n",
    "                           VI=np.linalg.inv(set_covariance),metric='mahalanobis') \n",
    "    \n",
    "    new_set = [True if d<cutoff else False for d in dists]\n",
    "    \n",
    "    if prior_set == new_set:\n",
    "        print('Converged!',counter,sum(new_set))\n",
    "        \n",
    "        return new_set, set_centroid, set_covariance, counter\n",
    "    \n",
    "    elif counter > counter_cutoff:\n",
    "        print('Too many iterations!',counter,sum(new_set))\n",
    "        \n",
    "        set_centroid = np.nanmean(data[new_set,:],axis=0)\n",
    "        set_covariance = np.cov(data[new_set,:].swapaxes(0,1))\n",
    "        \n",
    "        return new_set, set_centroid, set_covariance, counter\n",
    "    \n",
    "    else:\n",
    "        print('Still going!',counter,sum(new_set))\n",
    "        return classify_mutants(new_set,data,counter=counter+1,cutoff=cutoff,counter_cutoff=counter_cutoff)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a5d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling pure diploids and neutral haploids. According to 1 Day and 2 Day fitness (most accurate atm)\n",
    "ancestor_list = ['WT','CYR1','GPB2','TOR1','IRA1_MIS','IRA1_NON']\n",
    "ancestor_list = ['WT','CYR1','GPB2','TOR1','IRA1_MIS','IRA1_NON']\n",
    "# ancestor_list = ['CYR1']\n",
    "# calling_conditions = ['Fit1D_both2%5%_fitness','Fit2D_early_fitness','StaPerHour']\n",
    "\n",
    "calling_conditions = ['Fit1D_both2%5%_fitness','Fit2D_early_fitness','Fit5D_early_fitness','Fit3D_early_fitness']\n",
    "# calling_conditions = ['Fit1D_both2%5%_fitness','Fit2D_early_fitness','Fit3D_early_fitness','Fit5D_early_fitness']\n",
    "calling_errors = [col.replace('fitness','error') for col in calling_conditions]\n",
    "# plotting_conditions = ['Fit1D_both2%5%_fitness','Fit2D_early_fitness','Fit3D_early_fitness','Fit5D_early_fitness']\n",
    "plotting_conditions = ['FerPerHour','ResPerHour','StaPerHour']\n",
    "\n",
    "\n",
    "plotting_errors = [col.replace('fitness','error') for col in plotting_conditions]\n",
    "\n",
    "\n",
    "### prior for what's a haploid/diploid by eye\n",
    "haploid_cutoffs = {\n",
    "            'WT':[(-0.25,0.25),(-0.25,0.25),(-0.5,0.5),(-0.5,0.5)],\n",
    "            'CYR1':[(0.5,0.7),(1.0,2.0),(0.0,1.0),(1.0,2.0)],\n",
    "           'GPB2':[(0.5,0.7),(1.0,2.0),(-0.1,1.1),(1.0,2.0)],\n",
    "           'TOR1':[(0.4,0.6),(0.3,1.5),(-0.5,0.5),(0.3,1.5)],\n",
    "           'IRA1_MIS':[(0.5,0.7),(0.75,1.5),(-0.1,0.5),(0.25,0.75)],\n",
    "           'IRA1_NON':[[0.0,0.0],[0.0,0.0],(0.0,0.0),[0.0,0.0]]}\n",
    "\n",
    "diploid_cutoffs = {\n",
    "            'WT':[(0.25,0.5),(0.5,1.25),(-0.5,0.5),(-0.5,0.5)],\n",
    "            'CYR1':[(0.75,0.9),(1.5,2.5),(1.0,2.0),(1.5,2.5)],\n",
    "           'GPB2':[[0.72,0.9],[1.5,2.4],(0.5,1.8),[1.5,2.4]],\n",
    "           'TOR1':[[0.65,0.85],[1.25,2.25],(0.5,1.6),[1.25,2.25]],\n",
    "#            'IRA1_MIS':[[0.75,1.2],[1.4,2.2],(0.8,1.5)],\n",
    "            'IRA1_MIS':[[0.75,0.95],[1.4,2.2],(0.8,1.5),[0.75,1.5]],\n",
    "           'IRA1_NON':[[0.0,0.0],[0.0,0.0],(0.0,0.0),[0.0,0.0]]}\n",
    "\n",
    "to_sequence = {}\n",
    "missing_targets = {}\n",
    "already_sequenced = {}\n",
    "pure_diploid_dict = {}\n",
    "neutral_haploid_dict = {}\n",
    "\n",
    "for a,anc in enumerate(ancestor_list):\n",
    "    print(anc)\n",
    "    this_anc = merged_fitness[(merged_fitness['ancestor']==anc) & (merged_fitness['source_publication']!='Li2019')]\n",
    "#     for evo_cond in np.unique(this_anc['evolution_condition'].values):\n",
    "\n",
    "#     background_mutant = merged_fitness[merged_fitness['barcode']==tools.rebarcoding_source_mutants[anc]]\n",
    "    \n",
    "    dist_cutoff = 3.5\n",
    "\n",
    "    percentile_cutoff = 10\n",
    "\n",
    "    pure_diploids_prior = [True if np.all([x > diploid_cutoffs[anc][0][0],\n",
    "                               x < diploid_cutoffs[anc][0][1],\n",
    "                               y > diploid_cutoffs[anc][1][0],\n",
    "                               y < diploid_cutoffs[anc][1][1],\n",
    "                               z > diploid_cutoffs[anc][2][0],\n",
    "                               z < diploid_cutoffs[anc][2][1],\n",
    "                               q > diploid_cutoffs[anc][3][0],\n",
    "                               q < diploid_cutoffs[anc][3][1],\n",
    "                                    ]) else False\n",
    "                     for x,y,z,q in this_anc[calling_conditions].values]\n",
    "    print('Diploid, box:',sum(pure_diploids_prior))\n",
    "    \n",
    "    pure_diploids, pure_diploid_centroid, pure_diploid_cov, counter = classify_mutants(pure_diploids_prior,this_anc[calling_conditions].values,\n",
    "                                                                                      cutoff=dist_cutoff)\n",
    "    \n",
    "    pure_diploid_dict[anc] = list(this_anc['barcode'].values[pure_diploids])\n",
    "    \n",
    "    # first define by the manual boxes\n",
    "    neutral_haploids_prior = [True if np.all([x > haploid_cutoffs[anc][0][0],\n",
    "                               x < haploid_cutoffs[anc][0][1],\n",
    "                               y > haploid_cutoffs[anc][1][0],\n",
    "                               y < haploid_cutoffs[anc][1][1],\n",
    "                               z > haploid_cutoffs[anc][2][0],\n",
    "                               z < haploid_cutoffs[anc][2][1],\n",
    "                               q > haploid_cutoffs[anc][3][0],\n",
    "                               q < haploid_cutoffs[anc][3][1],\n",
    "                                       ]) else False\n",
    "                     for x,y,z,q in this_anc[calling_conditions].values]\n",
    "    print('Neutral, box:',sum(neutral_haploids_prior))\n",
    "\n",
    "    neutral_haploids, neutral_haploid_centroid, neutral_haploid_cov, counter = classify_mutants(neutral_haploids_prior,this_anc[calling_conditions].values,\n",
    "                                                                                               cutoff=dist_cutoff)\n",
    "\n",
    "\n",
    "    neutral_haploid_dict[anc] = list(this_anc['barcode'].values[neutral_haploids])\n",
    "#     neutral_haploid_centroid = np.nanmean(this_anc[calling_conditions].values[neutral_haploids,:],axis=0)\n",
    "#     neutral_haploid_cov = np.cov(this_anc[calling_conditions].values[neutral_haploids,:].swapaxes(0,1))\n",
    "#     dists = distance.cdist(this_anc[calling_conditions],[neutral_haploid_centroid])\n",
    "    ploidys = this_anc['ploidy_new'].values\n",
    "    bcs = this_anc['barcode'].values\n",
    "    colors = []\n",
    "    \n",
    "    haploid_fitness_dists = distance.cdist(this_anc[calling_conditions].values,[neutral_haploid_centroid]) \n",
    "    diploid_fitness_dists = distance.cdist(this_anc[calling_conditions].values,[pure_diploid_centroid])\n",
    "    \n",
    "    diploid_dists = distance.cdist(this_anc[calling_conditions].values,[pure_diploid_centroid],\n",
    "                           VI=np.linalg.inv(pure_diploid_cov),metric='mahalanobis') \n",
    "    haploid_dists = distance.cdist(this_anc[calling_conditions].values,[neutral_haploid_centroid],\n",
    "                           VI=np.linalg.inv(neutral_haploid_cov),metric='mahalanobis') \n",
    "    \n",
    "#     to_sequence[anc] = []\n",
    "#     missing_targets[anc] = [] \n",
    "#     already_sequenced[anc] = []\n",
    "    for entry in range(len(ploidys)):\n",
    "        newCloneID = this_anc['cloneID_new'].values[entry]\n",
    "        gene_from_previous_data = this_anc['additional_muts'].values[entry]\n",
    "        gene = this_anc['gene'].values[entry]\n",
    "        this_barcode = this_anc['barcode'].values[entry]\n",
    "#         old_class = this_anc['class'].values[entry]\n",
    "        \n",
    "        if pure_diploids[entry] == True:\n",
    "            if gene not in ['',np.nan,'Diploid','NotSequenced','Diploid-NotSequenced']:\n",
    "                colors.append('purple') # it was called pure diploid, but we found a putative causal mutation!\n",
    "                print('called pure diploid, found causal mutation',newCloneID,gene,ploidys[entry])\n",
    "            elif ploidys[entry] in ['diploid','Diploid']:\n",
    "                colors.append('#fc9272') # light red, it's called pure diploid and is diploid \n",
    "            else:\n",
    "#                 colors.append('#fee0d2') # very light red, it's called pure diploid but we didn't see ploidy on benomyl\n",
    "                colors.append('#fc9272') # very light red, it's called pure diploid but we didn't see ploidy on benomyl\n",
    "\n",
    "\n",
    "        elif neutral_haploids[entry] == True:\n",
    "            if gene not in ['',np.nan,'NotSequenced']:\n",
    "                colors.append('blue') # it was called pure haploid, but we found a putative causal mutation!\n",
    "                print('called neutral haploid, found causal mutation',newCloneID,gene,ploidys[entry])\n",
    "            elif ploidys[entry] in ['diploid','Diploid']:\n",
    "                colors.append('lightgray') # neutral haploid but ploidy called diploid\n",
    "            else:\n",
    "                colors.append('gray') # neutral haploid and ploidy is \n",
    "        else:\n",
    "            if gene in tools.mutation_color_map.keys():\n",
    "                colors.append(tools.mutation_color_map[gene])\n",
    "            elif ploidys[entry] in ['diploid','Diploid']:\n",
    "                if diploid_dists[entry] < 4:\n",
    "                    ### if there's a mutant that's kind of close, is diploid, has no called mutations, classify as diploid\n",
    "                    print('Calling as pure diploid',newCloneID,this_anc['all_mutations'].values[entry])\n",
    "                    colors.append('#fee0d2') \n",
    "                    pure_diploid_dict[anc].append(this_barcode)\n",
    "                \n",
    "                elif gene in ['']:\n",
    "                    colors.append('slategray')\n",
    "                else:\n",
    "                    colors.append('k')\n",
    "            \n",
    "            elif haploid_dists[entry] < 4:\n",
    "                print('Calling as neutral haploid',newCloneID,this_anc['all_mutations'].values[entry])\n",
    "                colors.append('silver') \n",
    "                neutral_haploid_dict[anc].append(this_barcode)\n",
    "            else:\n",
    "                if gene in ['']:\n",
    "                    colors.append('slategray')\n",
    "                else:\n",
    "                    colors.append('k')\n",
    "                    \n",
    "    \n",
    "    if anc != 'IRA1_NON':\n",
    "        \n",
    "        \n",
    "        diploid_dists = distance.cdist(this_anc[calling_conditions].values,[pure_diploid_centroid],\n",
    "                           VI=np.linalg.inv(pure_diploid_cov),metric='mahalanobis') \n",
    "        haploid_dists = distance.cdist(this_anc[calling_conditions].values,[neutral_haploid_centroid],\n",
    "                           VI=np.linalg.inv(neutral_haploid_cov),metric='mahalanobis') \n",
    "        \n",
    "        plt.figure(figsize=(8,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.scatter(haploid_dists,\n",
    "                        diploid_dists,\n",
    "                        color=colors,marker='.')\n",
    "        plt.xlabel('Haploid Distance')\n",
    "        plt.ylabel('Diploid Distance')\n",
    "        plt.axvline(dist_cutoff,color='k')\n",
    "        plt.axhline(dist_cutoff,color='k')\n",
    "        \n",
    "        plt.subplot(1,2,2)\n",
    "        haploid_fitness_dists = distance.cdist(this_anc[calling_conditions].values,[neutral_haploid_centroid]) \n",
    "        diploid_fitness_dists = distance.cdist(this_anc[calling_conditions].values,[pure_diploid_centroid])\n",
    "        plt.scatter(haploid_fitness_dists,\n",
    "                        diploid_fitness_dists,\n",
    "                        color=colors,marker='.')\n",
    "\n",
    "        plt.xlabel('Haploid Fitness Distance')\n",
    "        plt.ylabel('Diploid Fitness Distance')\n",
    "            \n",
    "    print(len(colors),len(ploidys))\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.suptitle(anc,y=0.9)    \n",
    "    \n",
    "    counter = 0\n",
    "    for c1,c2 in combinations(plotting_conditions,2):\n",
    "        c1_loc = np.where(np.isin(plotting_conditions,c1))[0][0]\n",
    "        c2_loc = np.where(np.isin(plotting_conditions,c2))[0][0]\n",
    "#         print(c1_loc+(c2_loc)*3+1)\n",
    "        plt.subplot(3,3,c1_loc+(c2_loc-1)*3+1)\n",
    "        plt.scatter(this_anc[c1],this_anc[c2],marker='.',color=colors)\n",
    "        plt.xlabel(c1)\n",
    "        plt.ylabel(c2)\n",
    "        counter+=1\n",
    "        if anc != 'WT':\n",
    "            background_mutant = merged_fitness[merged_fitness['barcode']==tools.rebarcoding_source_mutants[anc]]\n",
    "            plt.scatter(background_mutant[c1].values,background_mutant[c2].values,marker='+',color='k',s=100)\n",
    "\n",
    "#     plt.savefig(f'plots/WGS_targets_{anc}.pdf',bbox_inches='tight')\n",
    "    \n",
    "    plt.figure()\n",
    "    for entry in range(len(this_anc.index)):\n",
    "        plt.plot(this_anc[plotting_conditions].values[entry,:],color=colors[entry],alpha=0.4)\n",
    "    plt.xticks(range(len(plotting_conditions)),plotting_conditions)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae1b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b702aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_fitness[((merged_fitness['ancestor']=='IRA1_MIS') & \n",
    "#                (merged_fitness['FerPerHour']> 0.03) & \n",
    "#                (merged_fitness['FerPerHour']< 0.05 ) & \n",
    "#                (merged_fitness['ResPerHour']>0.04 ) & \n",
    "#                (merged_fitness['ResPerHour']<0.06 ) &\n",
    "#                (~p.isnull(merged_fitness['gene']))\n",
    "#                )][['barcode','gene','all_mutations','ploidy_new']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b997d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[merged_fitness['barcode'].isin(neutral_haploid_dict['IRA1_MIS'])][['barcode','gene','ploidy_new']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786291d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_new_list = []\n",
    "for anc,barcode,old_class,ploidy_new in zip(merged_fitness['ancestor'].values,\n",
    "                                            merged_fitness['barcode'].values,\n",
    "                                            merged_fitness['class'].values,\n",
    "                                            merged_fitness['ploidy_new'].values):\n",
    "    if anc in ['WT','CYR1','GPB2','TOR1','IRA1_MIS','IRA1_NON']:\n",
    "        if barcode in neutral_haploid_dict[anc]:\n",
    "            class_new_list.append('neutral_haploids')\n",
    "        elif barcode in pure_diploid_dict[anc]:\n",
    "            class_new_list.append('pure_diploids')\n",
    "        else:\n",
    "            if old_class == 'pure_diploids':\n",
    "                class_new_list.append('pure_diploids')\n",
    "            elif old_class == 'neutral_haploids':\n",
    "                class_new_list.append('neutral_haploids')\n",
    "            elif ploidy_new in (['diploid','Diploid']):\n",
    "                class_new_list.append('high_fitness_diploids')\n",
    "            else:\n",
    "                class_new_list.append('adaptive_haploid')\n",
    "        \n",
    "    else:\n",
    "        class_new_list.append(old_class)\n",
    "merged_fitness['class_new'] = class_new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04211fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_list = ['FerPerHour','ResPerHour','StaPerHour',\n",
    "                 'Fit1D_both2%5%_fitness''Fit2D_both2%5%_fitness','Fit2D_early_fitness','Fit3D_early_fitness','Fit5D_early_fitness']\n",
    "\n",
    "neutral_vals = {}\n",
    "\n",
    "for anc in ['WT','CYR1','GPB2','TOR1','IRA1_MIS','IRA1_NON']:\n",
    "    neutral_vals[anc] = {}\n",
    "    for performance in relative_list:\n",
    "        \n",
    "        if anc == 'WT':\n",
    "#             this_anc = merged_fitness[(merged_fitness['source_publication'] != 'Li2019') & \n",
    "#                                      (merged_fitness['ancestor']=='WT')]\n",
    "            \n",
    "            neutral_vals[anc][performance] = 0\n",
    "            \n",
    "            \n",
    "        elif anc == 'IRA1_NON':\n",
    "            background_mutant = merged_fitness[merged_fitness['barcode']==tools.rebarcoding_source_mutants[anc]]\n",
    "\n",
    "            neutral_vals[anc][performance] = background_mutant[performance].values[0]           \n",
    "            \n",
    "        else:\n",
    "            this_neutral_haploid = merged_fitness[(merged_fitness['ancestor']==anc) & \n",
    "                                                  (merged_fitness['class_new']=='neutral_haploids')]\n",
    "            \n",
    "            neutral_vals[anc][performance] = np.nanmean(this_neutral_haploid[performance].values)\n",
    "            \n",
    "            \n",
    "to_be_added = {}            \n",
    "            \n",
    "for performance in relative_list:\n",
    "    to_be_added[f'{performance}_relative'] = []\n",
    "    to_be_added[f'{performance}_ancestor'] = []\n",
    "    for barcode,anc,value in zip(merged_fitness['barcode'].values,\n",
    "                                        merged_fitness['ancestor'].values,\n",
    "                                       merged_fitness[f'{performance}'].values):\n",
    "        \n",
    "#         print(value)\n",
    "    \n",
    "        to_be_added[f'{performance}_relative'].append(value - neutral_vals[anc][performance])\n",
    "        to_be_added[f'{performance}_ancestor'].append(neutral_vals[anc][performance])\n",
    "        \n",
    "for performance in relative_list:\n",
    "    merged_fitness[f'{performance}_relative'] = to_be_added[f'{performance}_relative']\n",
    "    merged_fitness[f'{performance}_ancestor'] = to_be_added[f'{performance}_ancestor']\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b3c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "## additionally, remove some mutants where all fitnesses are close to ancestor and no mutations have been identified \n",
    "\n",
    "# filters = ['FerPerHour','ResPerHour','StaPerHour']\n",
    "# multiplier = 1\n",
    "\n",
    "# noisy_neutrals = (np.all(merged_fitness[filters].values+multiplier*merged_fitness[[f+'_error' for f in filters]].values>merged_fitness[[f+'_ancestor' for f in filters]].values,axis=1)&\n",
    "#             np.all(merged_fitness[filters].values-multiplier*merged_fitness[[f+'_error' for f in filters]].values<merged_fitness[[f+'_ancestor' for f in filters]].values,axis=1))\n",
    "# noisy_neutral_ixs = np.where(noisy_neutrals)[0]\n",
    "\n",
    "filters = ['Fit1D_both2%5%_fitness','Fit2D_early_fitness','Fit3D_early_fitness','Fit5D_early_fitness']\n",
    "\n",
    "multiplier = 2\n",
    "\n",
    "noisy_nonadaptives = (np.all(merged_fitness[filters].values-multiplier*merged_fitness[[f.replace('fitness','error') for f in filters]].values<merged_fitness[[f+'_ancestor' for f in filters]].values,axis=1))\n",
    "noisy_nonadaptive_ixs = np.where(noisy_nonadaptives)[0]\n",
    "\n",
    "# noisy_nonadaptives = (np.all(merged_fitness[filters].values+multiplier*merged_fitness[[f.replace('fitness','error') for f in filters]].values>merged_fitness[[f+'_ancestor' for f in filters]].values,axis=1)&\n",
    "#             np.all(merged_fitness[filters].values-multiplier*merged_fitness[[f.replace('fitness','error') for f in filters]].values<merged_fitness[[f+'_ancestor' for f in filters]].values,axis=1))\n",
    "\n",
    "\n",
    "# merged_fitness['class_new'] = [class_new if ((class_new in ['neutral_haploids','pure_diploids','high_fitness_diploids']) or (i not in noisy_neutral_ixs) or (not gene in [np.nan,'NotSequenced'])) else 'noisy_neutral' \n",
    "#                                for i,(class_new,gene) in enumerate(zip(merged_fitness['class_new'].values,merged_fitness['gene'].values))]\n",
    "\n",
    "merged_fitness['class_new'] = [class_new if ((class_new in ['neutral_haploids','pure_diploids','high_fitness_diploids']) or (i not in noisy_nonadaptive_ixs) or (not gene in [np.nan,'NotSequenced'])) else 'noisy_neutral' \n",
    "                               for i,(class_new,gene) in enumerate(zip(merged_fitness['class_new'].values,merged_fitness['gene'].values))]\n",
    "\n",
    "# print(merged_fitness[merged_fitness['class_new']=='noisy_neutral'][['barcode','ancestor','evolution_condition','gene']])                                           \n",
    "print(len(merged_fitness[merged_fitness['class_new']=='noisy_neutral']))    \n",
    "\n",
    "merged_fitness = merged_fitness[merged_fitness['class_new']!='noisy_neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d33bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### manually add double mutants with extreme fitness/performances:\n",
    "\n",
    "manual_doubles = {\n",
    "    'ATCACAATAACTAAACTGATTCTTCA_CTCATAACATCAAAAAAAATTCAAAT':\n",
    "        ['KSP1+TAN1','frameshift_variantstop_gained+missense_variant'],\n",
    "    'CCGCCAATCCCGAACCCCGTTTCGCC_ATGTTAACAAGAAAGACCTTTCTAAG':\n",
    "        ['ATE1+EEB1','missense_variant+stop_gained'],\n",
    "    'TATCGAAACCCAAAGAGATTTAATCG_CGATCAAAGACTAACTTATTTTGTGG':\n",
    "        ['IRA1+MKT1+SPB1','stop_gained+missense_variant+missense_variant'],\n",
    "    'CATTGAATCACAAAATAGGTTAGATG_CTCAAAAACAAAAATAAAATTGTTAC':\n",
    "        ['MKT1+SEC63','missense_variant+missense_variant'],\n",
    "}\n",
    "\n",
    "genes = []\n",
    "effects = []\n",
    "\n",
    "for barcode,gene,effect in zip(merged_fitness['barcode'].values,\n",
    "                               merged_fitness['gene'].values,\n",
    "                               merged_fitness['effect'].values):\n",
    "    if barcode in manual_doubles.keys():\n",
    "        genes.append(manual_doubles[barcode][0])\n",
    "        effects.append(manual_doubles[barcode][1])\n",
    "    else:\n",
    "        genes.append(gene)\n",
    "        effects.append(effect)\n",
    "        \n",
    "merged_fitness['gene'] = genes\n",
    "merged_fitness['effect'] = effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbef449",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness.to_csv(f'{home_dir}/data/fitness_withMutations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a76ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([entry for entry in merged_fitness[(merged_fitness['ancestor']=='WT') & \n",
    "                                             (merged_fitness['source_publication']!='Li2019')\n",
    "                                            ]['class'].values if not p.isnull(entry)],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2fcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[(merged_fitness['ancestor']=='WT') & \n",
    "                                             (merged_fitness['source_publication']!='Li2019')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[(merged_fitness['ancestor']=='TOR1') &\n",
    "              (merged_fitness['evolution_condition']=='Evo2D') \n",
    "#                & \n",
    "#                (merged_fitness['class_new'].isin(['adaptive_haploid','high_fitness_diploid'])) \n",
    "              ]['gene'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0be137",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness['MTH1' in merged_fitness['all_mutations_verbose']]['gene'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcs_of_interest = []\n",
    "\n",
    "for a,all_muts in enumerate(merged_fitness['all_mutations_verbose']):\n",
    "    if not p.isnull(all_muts):\n",
    "        if 'MTH1' in all_muts:\n",
    "            print(merged_fitness['barcode'].values[a])\n",
    "            bcs_of_interest.append(merged_fitness['barcode'].values[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[merged_fitness['barcode'].isin(bcs_of_interest)][['ancestor','gene','class_new','all_mutations']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_anc = merged_fitness[merged_fitness['ancestor']=='IRA1_NON']\n",
    "\n",
    "plt.scatter(this_anc['FerPerHour'],this_anc['ResPerHour'])\n",
    "\n",
    "these_bcs = this_anc[this_anc['barcode'].isin(bcs_of_interest)]\n",
    "\n",
    "plt.scatter(these_bcs['FerPerHour'],these_bcs['ResPerHour'])\n",
    "plt.figure()\n",
    "this_anc = merged_fitness[merged_fitness['ancestor']=='IRA1_NON']\n",
    "\n",
    "plt.scatter(this_anc['ResPerHour'],this_anc['StaPerHour'])\n",
    "\n",
    "these_bcs = this_anc[this_anc['barcode'].isin(bcs_of_interest)]\n",
    "\n",
    "plt.scatter(these_bcs['ResPerHour'],these_bcs['StaPerHour'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[(merged_fitness['ancestor']=='IRA1_MIS') & (merged_fitness['FerPerHour']<0.002)][['ancestor','gene','class_new','all_mutations']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1390b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[(merged_fitness['ancestor']=='CYR1') & (merged_fitness['ResPerHour']>0.09)][['ancestor','gene','class_new','all_mutations']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38127252",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fitness[merged_fitness['gene']=='MTH1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0371406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_fitness[((merged_fitness['ancestor']=='WT') & \n",
    "                (merged_fitness['source_publication']!='Li2019') &\n",
    "               (merged_fitness['FerPerHour']> 0.006) & \n",
    "               (merged_fitness['FerPerHour']< 0.02 ) & \n",
    "               (merged_fitness['ResPerHour']>0.035 ) & \n",
    "               (merged_fitness['ResPerHour']<0.06 ) \n",
    "#                 &\n",
    "#                (~p.isnull(merged_fitness['gene']))\n",
    "               )][['barcode','gene','all_mutations','ploidy_new']].values)\n",
    "\n",
    "this_data = merged_fitness[(merged_fitness['ancestor']=='WT') & (merged_fitness['source_publication']!='Li2019')]\n",
    "colors_here = []\n",
    "for old_class in this_data['class'].values:\n",
    "    if old_class == 'neutral_haploids':\n",
    "        colors_here.append('gray')\n",
    "    elif old_class == 'pure_diploids':\n",
    "        colors_here.append('r')\n",
    "    else:\n",
    "        colors_here.append('k')\n",
    "\n",
    "plt.scatter(this_data['FerPerHour'],\n",
    "            this_data['ResPerHour'],c=colors_here)\n",
    "plt.axvspan(0.01,0.02,alpha=0.2)\n",
    "plt.axhspan(0.035,0.06,alpha=0.2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evolvingfront-venv",
   "language": "python",
   "name": "evolvingfront-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
